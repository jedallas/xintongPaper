\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
%\usepackage{colorlinks, linkcolor=red}{hyperref}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{An Ensemble Learning Algorithm for Indoor Localization Using Mobile Phone-Based Sensors\\  %Title
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Xintong Wang}
\IEEEauthorblockA{\textit{Department of Software Engineering} \\
\textit{Harbin Institute of Technology}\\
Weihai, China \\
150730121@stu.hit.edu.cn}
\and
\IEEEauthorblockN{Yunfei Feng}
\IEEEauthorblockA{\textit{Sam's Club Technology} \\
\textit{ Wal-Mart Inc.}\\
Bentonville, Arkansas, USA \\
yunfei.feng@samsclub.com}
}

\maketitle

\begin{abstract}
In this paper, we investigated the problem of localizing a smartphone with iBeacon signal strengths utilizing an ensemble learning algorithm.
We built a real testing environment and examined the performance of the ensemble learning algorithm in our positioning system that outperformed any single classifier individually.
We also proposed two approaches to improve the accuracy: Exponentially Weighted Moving Averages to deal with wireless signal fluctuation, and data augmentation for enlarging existing data volume.
Further, the extent of the density received signal affecting the accuracy of localization by using different intervals was discussed.
Most importantly, we tested our algorithm in a real environment. % and demonstrated that these  approaches are appropriate for real-world applications but the problem of overfitting remains outstanding.
In order to fight against overfitting, data balancing on training datasets in each reference point was introduced.
%and of fluctuating and a weighted fusion algorithm to synthesize predictions of multiple datasets for a better performance.
By a series of comprehensive experiments, We have corroborated that the weighted ensemble learning algorithm is capable of localization with high accuracy.

\end{abstract}

\begin{IEEEkeywords}
Indoor localization, machine learning, ensemble learning, iBeacon
\end{IEEEkeywords}

\section{Introduction}
Indoor localization has gained a lot of interests in the market. Its applications are pervasive, such as security surveillance\cite{b1}, robotics applications\cite{b2}, and path navigation\cite{b3} in places such as shopping malls, airports, and hospitals.
One observation is that higher accuracy is often achieved in a situation with more obstacles\cite{b4}, i.e. shopping mall, hospital, campus, and office building.
In contrast, it is hard to reach a satisfactory accuracy in an open spacious area.
Thus this work focuses on the indoor localization in open spacious areas.

Machine learning algorithms have been widely approved on improving classification performance. %reduce computation time due to
In the meantime, it provides excellent solutions to discover hidden patterns and potential trends. %, which is often difficult or impossible for other methods.
In this work, supervised learning algorithms for classification were adopted and ensemble learning algorithms were employed to synthesize different predictions of each algorithm.
As more training dataset is usually able to improve the performance, we proposed two approaches to enlarge our existing datasets: one is to amend the fluctuating signals and discover a hidden pattern, another is to combine the specific dataset and pattened dataset into one comprehensive dataset.

In this study, the whole system is divided into two phases: an offline phase for capturing signals and training an accurate model; an online phase for classifying on the fly.
During the offline phase, we present an approach to balance data, which have significant contributions to alleviate overfittings.
Moreover, a weighted fusion algorithm on the final decision making stage  comprehensively leads to an accurate performance: 96\% accuracy.

The paper is organized as follows.
Section II summarizes other indoor localization systems and machine learning algorithms for indoor localization.
Section III describes the process of data collection, processing, the experiments, and our system.
Section IV presents the results of our analysis in different environments and its performance in a real environment.
Hereby, two approaches to solve the problem of overfitting are discussed.
Finally, the paper concludes with some ideas for further work in Section V.

\section{RELATED WORK}
Researchers have proposed some technologies to underlie an indoor positioning system (IPS), including ultrasound\cite{b5}, RFID \cite{b6}. Visible lights communication\cite{b7} is another advanced trial in academia. While wireless signal-based indoor positioning systems, such as Bluetooth\cite{b8}\cite{b9} and WiFi\cite{b10}\cite{b11}, have made a great success in industry.
Smartphones with a plug-in Bluetooth Low Energy(BLE) module are popular nowadays, thus iBeacon technology is an alternative for IPS.
Basically three major kinds of principles are convincing: fingerprinting by Received Signal Strength Indication (RSSI) \cite{b12}\cite{b13},
trilateration\cite{} by distances computing and triangulation\cite{} by relative
positions compared to each access point.

Machine learning algorithms become widely utilized for classification recently, even in the positioning area.
K-Nearest Neighbor algorithm has been revealed as the most suitable model during positioning\cite{b14}.
An improved precision yielded by the model in conjunction with support vector machine, ensemble SVR, and artificial neural network has been demonstrated, as compared to an independent model\cite{b15}.
The results show that the performance of K-Nearest Neighbors, decision tree and Support Vector Machine (SVM) outperform other indoor localization methods both in computation time and precision\cite{b16}.
Also, the combination of K*algorithm\cite{b17} and Radial Basis Function (RBF) Regression are demonstrated as the most accurate model among 20 machine learning algorithms\cite{b18}.
However, few researchers made efforts on an ensemble learning estimating algorithm, which combines multiple learning algorithms to obtain a better performance.

\begin{comment}
Traditional fingerprinting approach which we will utilize in this paper can be divided into two phases: offline phase and online phase.
During the offline phase, the location and respective iBeacon signal strengths from access points are collected.
During the online phase, a location positioning technique uses the currently observed signal strengths and previously collected information to figure out an estimated location.
After collection, we use 2 approaches to process data for further training our system.
During the online phase, we test this system in real-world use and proposed 2 approaches to handle the downside found in online phase.
The system built for an algorithm can be easily implemented as part of an application and installed for localization on the device itself.
\end{comment}

In this paper, we mainly focus on applying an ensemble algorithm on the RSSI fingerprinting to develop an IPS.

\section{METHODOLOGY}
The localization process consists of three phases: data collection, processing
and analysis. Prior to collecting data, some deployments are certainly
necessary, such as predefining testing points and deploying the iBeacon devices.
As magnetic fields signals would not remain constant, we don't take them into consideration. After deployment and collection, some approaches are utilized for processing, such as EWMA and data augmentation. In the end, machine learning algorithms for classifications are applied.

\subsection{Exponentially Weighted Moving Averages}
A sophisticated optimization algorithm called exponentially weighted averages is introduced, which is also called Exponentially Weighted Moving Averages (EWMA) in statistics or Exponential Smoothing \cite{b19}. As shown in Eq.\ref{eq:1},
\begin{equation}
\label{eq:1}
S_t=\left\{
                \begin{array}{lrl}
                Y_t & & {t=1}\\
                \alpha {Y_t} + (1 - \alpha ){S_{t - 1}}& & {t>1}
                \end{array}
\right.
\end{equation}

where it eventually gets $S_t$ as a weighted sum of the temporal data points $Y_t$ as:
\begin{align}
  {S_t}  &=\alpha {Y_t} + (1 - \alpha ){S_{t - 1}}       \\
             &= (1 - \alpha )((1 - \alpha ){S_{t - 2}} + \alpha {Y_{t - 1}}) + \alpha {Y_t} \\
             &= \sum\limits_{m = 0}^\infty  {\alpha {{\left( {1 - \alpha } \right)}^m}{Y_{n - m}}}
\end{align}

Initializing $Y_1$ as the first value in a series of signal strengths and then, on every record of sampling, it gets a averaging process with a weight of $\alpha$ times appearing as the previous value, and involves 1-$\alpha$ times the new signal strength. Here the parameter $\alpha$ indicates the total number of last involved records to calculate a weighted average.

Fig.\ref{fig:1} shows an excerpt of signal strengths received by an Android App, \textit{iBeacon signal collector}.
In order to compute the trend on the drastically fluctuating raw data, EWMA is adopted to obtain a much smoother curve by amending the fluctuating and finding a hidden pattern.
signals and discover a hidden pattern,
\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth] {fig1.pdf}
\caption{Original iBeacon signals strengths and those smoothened by EWMA processing with various $\alpha$s. }
\label{fig:1}
\end{figure} %纵坐标应该是RSSI， not fingerprinting

\subsection{Experiment Design and Data Collection}
Our first study case took place in a spacious lab with 14 meter wide and 18 meter long.
Totally, 12 testing points were predefined in the lab.
Two rounds of experiments were conducted in the lab, which had 23 iBeacon devices and 9 iBeacon devices, respectively
. The layout of lab and distribution of multiple iBeacon devices are shown in Fig.\ref{fig:2} and Fig.\ref{fig:3}.
The height of each iBeacon is marked in figures.
The label by each iBeacon represents the Minor value and two rightmost digits of BSSID (MAC address).
Each iBeacon advertises in 100 ms interval.

\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth]{fig2.pdf}
\caption{Experiment 1: The layout of lab and the distribution of 23 iBeacon devices.}
\label{fig:2}
\end{figure}

\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth]{fig3.pdf}
\caption{Experiment 2: The layout of lab and the distribution of 9 iBeacon devices.}
\label{fig:3}
\end{figure}

Later, another experiment took place in a real supermarket with 36 meter wide and 50 meter long.
Totally, 92 iBeacon devices were deployed and 31 testing points was selected. %, shown in Fig.\ref{fig:4}.
Each iBeacon advertises in 100 ms interval as well.
Up to now, three experiments datasets were generated.

\begin{comment}
\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth]{fig4.pdf}
\caption{Experiment 3: The layout of a real supermarket.}
\label{fig:4}
\end{figure}
\end{comment}

\subsection{System and Data Flow}
The Android App, \textit{iBeacon signal collector}, ran on a Huawei Honor 9 smartphone.
In the offline signal collection phase, the collector stayed on each testing points for 2 minutes to capture iBeacon information until traversing all testing points.
The iBeacon information was logged into a csv file stored on the server.
In each recording instance, six attributes were logged, including time, iBeacon device name, BSSID (MAC address), Minor value, RSSI and testing point id.

In the preprocessing stage, the system applied EWMA technique with various $\alpha$ values on the raw dataset,
and converted it into the acceptable input format for the machine learning classifier.
After preprocessing, an ensemble learning algorithm was adopted to train a localization estimation system on the entire dataset.
Then we evaluated the ensemble classifier in the metrics of accuracy and average error distance.
The aforementioned algorithm was implemented based on the Python scikit-learn module.

\section{RESULTS AND DISCUSSIONS}
Our analysis has two different phases: offline and online.
The offline analysis presents the performance of each algorithm alone and the ensemble learning algorithm in predicting a position on the different datasets.
While the online analysis will utilize the model trained in offline phase to
keep track of a user's real-time iBeacon fingerprints and predict his/her location.

\subsection{Offline Phase}
We examined the performances of 9 machine learning algorithms perspectively and the ensemble learning algorithm on our dataset using 10-fold cross-validation in the metrics of accuracy. Here, the whole training dataset was evaluated as a test dataset.
Table \ref{tab:1} manifests the accuracy for each algorithm and that of the ensemble algorithm.
Here the ensemble learning algorithm managed to achieve a high accuracy of 94.10\%.
Although none of the solo algorithms performed well enough, the ensemble algorithm produced an amazing outcome.

\begin{table}[htbp]
\caption{ACCURACY IN POSITIONING SYSTEM ON A TESTING DATASET}
\begin{center}
\begin{tabular}{|l|r|}
\hline
Algorithm& Accuracy\\
\hline
K-Nearest Neighbor&	22.14\%\\
Linear SVM	&14.32\%\\
RBF SVM	&11.34\%\\
Decision Tree	&22.97\%\\
Random Forest	&31.74\%\\
Neural Networks	&24.71\%\\
AdaBoost	&43.04\%\\
Naive Bayes	&16.05\%\\
Quadratic Discriminant Analysis	&21.52\%\\
Ensemble learning	  &94.10\%\\
\hline
\end{tabular}
\label{tab:1}
\end{center}
\end{table}

As aforementioned, EWMA method was introduced in the preprocessing stage. By
varying average-$\alpha$, averaged datasets were generated. Afterwards, one
ensemble dataset was generated by combining the original raw dataset and one
averaged dataset.

%Average-$\alpha$ is a dataset optimized by EWMA using the corresponding Raw dataset to discover a general pattern and trend in this data, and $\alpha$ is a parameter in EWMA approach can be set as 0.5, 0.7 and 0.9 in lab 1,2 and 0.7, 0.9, 0.95, 0.97 and 0.99 in lab 3.
Table \ref{tab:2} shows the results of experiment 1, while the results of experiment 2 is shown in Table \ref{tab:3}.
Here, an approach for data augmentation is utilized.
Ensemble-$decimal$ is a dataset consisting of the raw dataset and the
"Average-$decimal$" dataset, which is a processed dataset by setting EWMA
parameter average-$\alpha$ as the $decimal$.

\begin{table}[htbp]
\caption{ACCURACY OF POSITIONING SYSTEM IN EXPERIMENT 1}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Model(23)& 100 ms interval& 600 ms interval\\
\hline
Raw data    & 55.49\%, 4.1494m & 92.15\%, 0.5656m\\
Average0.5  & 57.02\%, 3.9231m & 94.72\%, 0.4425m\\
Average0.7  & 58.91\%, 3.8544m & 95.72\%, 0.3485m\\
Average0.9  & 62.98\%, 3.4800m & 92.58\%, 0.5803m\\
Ensemble0.5 & 88.51\%, 1.0345m & 94.58\%, 0.4329m\\
Ensemble0.7 & 94.10\%, 0.5672m & 95.15\%, 0.3771m\\
Ensemble0.9 & 87.55\%, 1.1638m & 93.44\%, 0.5303m\\
\hline
\end{tabular}
\label{tab:2}
\end{center}
\end{table}

\begin{table}[htbp]
\caption{ACCURACY OF POSITIONING SYSTEM IN EXPERIMENT 2}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Model(9)& 100 ms interval& 600 ms interval\\
\hline
Raw data	&56.50\%, 4.0060m	&70.17\%, 2.5689m\\
Average0.5	&63.11\%, 3.1527m	&81.27\%, 1.6291m\\
Average0.7	&78.53\%, 1.8325m	&83.57\%, 1.3929m\\
Average0.9	&90.05\%, 0.8308m	&86.17\%, 1.1693m\\
Ensemble0.5	&74.78\%, 2.2847m	&89.20\%, 0.9217m\\
Ensemble0.7	&77.09\%, 1.9534m	&87.03\%, 1.0345m\\
Ensemble0.9	&79.88\%, 1.7851m	&87.39\%, 0.9828m\\
\hline
\end{tabular}
\label{tab:3}
\end{center}
\end{table}

A comparison of the six best performances is illustrated in
a Cumulative Distribution Function (CDF) diagram Fig.\ref{fig:5}.
%of localization distance errors.
\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth] {fig5.pdf}
\caption{CDF comparison of 6 excellent models.}
\label{fig:5}
\end{figure}

Note that the datasets recorded within a 600 ms interval generally perform much
better than recorded within 100 ms, because a fingerprint in 600 ms has more
information of more involved iBeacon devices.
Obviously the experiment of "23 iBeacon 600 interval average 0.7" significantly outperforms the other schemes.
These results indicate that our method of using average dataset and ensemble
dataset is able to utilize in a real-world scenario.
Surprisingly, the 95\% errors of the three best systems are within close to 0m, 0m, and 0.5m respectively.
It demonstrates that the best system is able to limit the majority of errors into an acceptable range.
Meanwhile, those sessions with 23 iBeacon devices in experiment 1 primarily surpasses than those with 9 iBeacon devices in experiment 2.

%We not only tested whether the ensemble learning algorithm outperforms than the other algorithms alone but also were also curious about whether the performance of ensemble dataset could outperform than raw dataset and average dataset as more data is used for training and whether each dataset processed by EWMA have a better performance than the corresponding raw dataset.
%The dataset using EWMA approach and data augmentation results in slightly increased accuracy for data recorded within 600 ms interval and significantly increased accuracy for data recorded within 100 ms.
%According to the significant improvement in comparing the performance of 100 ms dataset and 600 ms dataset, this slight improvement leads us to believe that the denser dataset results in a better performance.
%Also, the truth that lab 1 using 23 iBeacon devices outperform than lab 2 using 9 iBeacon devices may corroborate that more iBeacon devices for deployment in positioning system can enhance the accuracy.

\begin{table}[htbp]
\caption{ACCURACY OF POSITIONING SYSTEM IN EXPERIMENT 3}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Model(92)& 600 ms interval& 900 ms interval\\
\hline
Raw data     & 93.83\%, 0.4631m & 93.89\%, 0.4582m\\
Average0.7   & 93.95\%, 0.4544m & 99.61\%, 0.0291m\\
Average0.9   & 94.23\%, 0.4333m & 99.92\%, 0.0056m\\
Average0.95  & 97.06\%, 0.2201m & 99.92\%, 0.0057m\\
Average0.97  & 96.83\%, 0.2380m & 99.92\%, 0.0055m\\
Average0.99  & 96.31\%, 0.2771m & 99.61\%, 0.0294m\\
Ensemble0.7  & 93.69\%, 0.4746m & 93.89\%, 0.4587m\\
Ensemble0.9  & 93.75\%, 0.4703m & 93.82\%, 0.4700m\\
Ensemble0.95 & 95.10\%, 0.3681m & 94.47\%, 0.4202m\\
Ensemble0.97 & 94.78\%, 0.3928m & 94.82\%, 0.3941m\\
Ensemble0.99 & 94.75\%, 0.3946m & 95.05\%, 0.3779m\\
\hline
\end{tabular}
\label{tab:4}
\end{center}
\end{table}

In experiment 3, we deployed 92 iBeacon devices in a real spacious supermarket. Various
Average-$\alpha$ values with 600 ms and 900 ms intervals were analyzed. Table\ref{tab:4} shows the results.

Unlike the previous experiments, the average datasets outperform their corresponding ensemble datasets.
Although amazing high accuracy has been achieved by those average datasets,
ensemble datasets still perform an excellent matching rate between the newly observed
fingerprints and existing fingerprints.
% observed signal strengths and existing signal strengths.
So to speak, ensemble datasets is able to further alleviate the overfittings compared with those average datasets.


%and show good robustness which average datasets sometimes can’t show.  ?????? 鲁棒性-> ensemble有效减少了overfittings
%meaning?

To summarize, % the results in this table corroborate that
(1) a denser dataset has a higher chance to yield a better performance; %, as the comparison of 100 ms interval, 600 ms interval, and 900 ms interval.
(2) data averaging and data augmentation are helpful to increase the accuracy.
%using average dataset and ensemble dataset to enlarge the amount of data for training is a useful and effective approach.

\subsection{Online Phase}
In the offline phase, we trained the ensemble learning algorithm for the best performance on different datasets and saved it.
In the online phase, the system processes a user's on-the-fly fingerprints and localizes him/her.

Applications such as location based service, security surveillance, path
prediction and heat map analysis can be satisfied by an indoor positioning
system. In reality, the indoor positioning algorithm is capable in various
occasions, such as shopping malls, factories, warehouses, parking lots, etc.
%However, there are still many problems faced by both the areas of industry and academia.
%When it comes to real-world and real-time utilization, industrial utilization has been achieved in the areas of

\subsubsection{Device sustainability}
In a real environment, iBeacon devices may suffer from many interferences. For
example, someone may take one of the iBeacon devices away, replace it
somewhere, or an iBeacon device suddenly turns defunct for some reason (might be broken or out of electricity,) so that it doesn't broadcast any signal.
All these factors lead to an inconsistent RSSI environment from the past.
The system should provide some mechanisms to detect those abnormal iBeacons and some actions should be taken.

While the results after keeping signal strengths can be seen in Table\ref{tab:3}.
Table\ref{tab:3} in experiment 2 shows the result with 9 iBeacon devices.
This round of experiment is interesting. One iBeacon device was removed from the
scenario in experiment 2, and Table \ref{tab:5} shows the result.
Comparing the two tables with the same 600 ms interval, the scenario of 8
iBeacon devices has a visible performance loss.

\begin{table}[htbp]
\caption{ACCURACY OF POSITIONING SYSTEM IN EXPERIMENT 2 WITH AN IBEACON LOST. ??????????????????????????? 和table3数据重复，而且怎么可能性能有提高????????}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Model(8)& 100 ms interval& 600 ms interval\\
\hline
Raw data&	    67.07\%, 2.9853m&	70.17\%, 2.5689m\\
Average0.5&	    75.29\%, 2.0799m&	81.27\%, 1.6291m\\
Average0.7&	    81.43\%, 1.5264m&	83.57\%, 1.3929m\\
Average0.9&	    91.74\%, 0.6788m&	86.17\%, 1.1693m\\
Ensemble0.5&	83.60\%, 1.4041m&	89.20\%, 0.9217m\\
Ensemble0.7&	80.74\%, 1.6885m&	87.03\%, 1.0345m\\
Ensemble0.9&	82.34\%, 1.5190m&	87.39\%, 0.9828m\\
\hline
\end{tabular}
\label{tab:5}
\end{center}
\end{table}

\subsection{Overfitting Issue}
Unfortunately but not surprisingly, overfitting happened in our system. The experiment 3 tested in a real supermarket where 109 iBeacon devices were deploy.
The system usually has an excellent performance when evaluating on the entire training dataset, however it can not perform extraordinary when evaluating on a training dataset and a test dataset splitted from a whole dataset.
%The ensemble dataset which can reach 99.6 percent accuracy on the training data but 78.6 percent on the testing data is not a functional system in real-world applications.
%Faced with its low accuracy,
Accordingly, we proposed two approaches to fight against overfitting, data balance and data augmentation.
Balancing data is an excellent approach for diminishing training preference caused by different amount of the data.
The objective of balancing data is to make sure the training dataset has totally
equal data volume on each testing point in the experiment environment.
%equal the amount of data on each reference point by randomly cutting the amount of each dataset down to a minimum determined by the smallest amount.
%As you can see from Table V, the best ensemble balance system outperforms corresponding traditional ensemble system with 86.6 percent accuracy.  // where?????
%However, that is still not accurate enough for real-world use.
%Considering that after cutting down the amount, there is not much data for building an accurate system because less data usually leads to lower accuracy.
To ensure an adequate data, data is augmented by averaging and combining.
Eventually, it reached a satisfactory accuracy and low average error distance,
shown in Table\ref{tab:6}.
%Eventually, the performance of 95.5 percent accuracy and 0.5558 m average error distance has been achieved. //where???

\begin{table}[htbp]
\caption{ ACCURACY OF POSITIONING SYSTEM IN EXPERIMENT 3}
\begin{center}
\begin{tabular}{|l|r|r|}
\hline
Model(109)& Accuracy	&Average Error Distance\\
\hline
100ms               & 11.53\% & 16.5489m\\
100ms[Balance]      & 29.18\% & 12.3396m\\
100ms[Average0.7]   & 12.44\% & 15.7700m\\
Average0.7[Balance] & 26.84\% & 12.7915m\\
Ensemble            & 19.82\% & 15.5851m\\
Ensemble[Balance]   & 57.32\% & 7.8511m\\
600ms               & 30.07\% & 9.1704m\\
600ms[Balance]      & 46.26\% & 7.2193m\\
600ms[Average0.7]   & 27.92\% & 10.0704m\\
Average0.7[Balance] & 42.61\% & 7.9747m\\
Ensemble            & 80.15\% & 2.7173m\\
Ensemble[Balance]   & 86.18\% & 1.8908m\\
900ms               & 28.70\% & 9.9972m\\
900ms[Balance]      & 39.90\% & 7.9225m\\
900ms[Average0.7]   & 27.96\% & 9.6679m\\
Average0.7[Balance] & 40.66\% & 8.2185m\\
Ensemble            & 78.36\% & 2.8189m\\
Ensemble[Balance]   & 86.57\% & 1.8689m\\
\hline
\end{tabular}
\label{tab:6}
\end{center}
\end{table}

\begin{figure}[thpb]
\centering
%\centerline{\includegraphics{fig2.png}}
\includegraphics[width=\linewidth] {fig6.pdf}
\caption{Confusion matrix of the best experiment result.}
\label{fig:6}
\end{figure}

Fig. \ref{fig:6} is a modified confusion matrix. The numbers on the diagonal line
represent the total number of correct classification instances. There are
another four types of notations in the matrix.
"0" means there is not any misclassification in this instance;
"1" means there are some misclassifications in the original raw dataset;
"2" means there are some misclassifications in either the averaging dataset or ensembling dataset;
"3" means there are some misclassifications in both the original raw dataset and the two transformed dataset.
That is to say, the instance with a notation "3" is hard to make an accurate prediction using data augmentation. (?????????? %我解释的对吗?）

One step further, we tried to improve by a weighted fusion algorithm:
The final prediction is decided by a list of weights multiplies the probabilities associated with different datasets.
For example, if the same record is predicted improperly in at least 2 datasets
among raw dataset and 2 transformation datasets, we recognized it as a false
detection. In the meantime, we considered one misclassification as a true detection. (?????????????? %没明白你的算法)
In this way, a more accurate performance has been achieved: 96.5\%.
Moreover, gradient descent optimization is able to modify different weights to
achieve a better accuracy rate.

\section{CONCLUSIONS AND FUTURE WORK}
In this work, we have tested 9 machine learning algorithms and an ensemble
learning algorithm for indoor localization based on the iBeacon devices deployed
in three experiment environments. The \textit{iBeacon signal collector} App was
developed to capture iBeacon information.
We have found that the ensemble algorithm outperforms any single algorithms in a real-world environment.
Besides, experiment results indicated that more iBeacon devices can be applied to have a more accurate detection without any infrastructure changes.

During data preprocessing period, the time interval of receiving signals makes a significant impact on the prediction accuracy.
A longer interval leads to a higher accuracy since the RSSI fingerprints has more iBeacon information.
In addition, the techniques of EWMA and data augmentation boost the performances substantially.
%In this system, offline and online phases have been split for distinct missions.
%We also tested our system in real supermarket and proposed two approaches to solve the problem of overfitting.

In the future, we will explore multiple wireless devices (e.g. Bluetooth or ZigBee) to broadcast signal, so that a receiver could capture different signal strengths at each predefined reference point.
Hence the system more valuable information could be leveraged to localize one device.
%We also intend to look into and explore how the density of our collecting dataset could influence the performance of the system.
%We will try a longer interval and test its performance.
%We will utilize more approaches for processing our data, not only EWMA and data augmentation.
%Futhermore, we will build a complete system providing more techniques such as path prediction and heat map analysis using positioning system and face recognition.

\section*{}
\begin{thebibliography}{00}
\bibitem{b1} Monroe D A. Network communication techniques for security surveillance and safety system: US, US 6392692 B1[P]. 2002.
\bibitem{b2} Sohn B, Lee J, Chae H, et al. Localization system for mobile robot using wireless communication with IR landmark[C]// International Conference on Robot Communication and Coordination. IEEE Press, 2007:6.
\bibitem{b3} Stook J. Planning an indoor navigation service for a smartphone with Wi-Fi fingerprinting localization[J]. Otb Research Institute for the Built Environment, 2011.
\bibitem{b4} Lin T H, Ng I H, Lau S Y, et al. A Microscopic Examination of an RSSI-Signature-Based Indoor Localization System[J]. 2008.
\bibitem{b5} N. B. Priyantha, A. Chakraborty and H. Balakrishnan, “The Cricket Location-Support System,” Proceedings of MobiCom 2000, Boston, 6-10 August 2000, pp. 32-43.
\bibitem{b6} Hahnel D, Burgard W, Fox D, et al. Mapping and localization with RFID technology[C]// IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA. IEEE, 2004:1015-1020.
\bibitem{b7} Kavehrad M, Deng P. Indoor positioning algorithm using light-emitting diode visible light communications[J]. Optical Engineering, 2012, 51(8):5009.
\bibitem{b8} Aalto L, Korhonen J, Ojala T. Bluetooth and WAP push based location-aware mobile advertising system[C]// International Conference on Mobile Systems, Applications, and Services. DBLP, 2004:49-58.
\bibitem{b9} Bruno R, Delmastro F. Design and Analysis of a Bluetooth-Based Indoor Localization System[C]// Personal Wireless Communications, Ifip-Tc6, International Conference, Pwc 2003, Venice, Italy, September 23-25, 2003, Proceedings. DBLP, 2003:711-725.
\bibitem{b10} Paul A S, Wan E A. Wi-Fi based indoor localization and tracking using sigma-point Kalman filtering methods[C]// Position, Location and Navigation Symposium, 2008 IEEE/ION. IEEE, 2008:646-659.
\bibitem{b11} Goswami A, Ortiz L E, Das S R. WiGEM:a learning-based approach for indoor localization[C]// Conference on Emerging NETWORKING Experiments and Technologies. ACM, 2011:1-12.
\bibitem{b12} Kaemarungsi K, Krishnamurthy P. Modeling of indoor positioning systems based on location fingerprinting[C]// Joint Conference of the IEEE Computer and Communications Societies. IEEE, 2004:1012-1022 vol.2.
\bibitem{b13} Zhao, K.; Li, B.; Andrew, D.; Chen, L. A Comparison of algorithms adopted in fingerprinting indoor positioning systems. In Proceedings of the International Global Navigation Satellite Systems Society IGNSS Symposium, Outrigger Gold Coast, Australia, 16C18 July 2013.
\bibitem{b14} Bozkurt S, Elibol G, Gunal S, et al. A comparative study on machine learning algorithms for indoor positioning[C]// International Symposium on Innovations in Intelligent Systems and Applications. IEEE, 2015:1-8.
\bibitem{b15} Cheng Y K, Chou H J, Chang R Y. Machine-Learning Indoor Localization with Access Point Selection and Signal Strength Reconstruction[C]// IEEE, Vehicular Technology Conference. IEEE, 2016:1-5.
\bibitem{b16} Salamah A H, Tamazin M, Sharkas M A, et al. An enhanced WiFi indoor localization system based on machine learning[C]// International Conference on Indoor Positioning and Indoor Navigation. IEEE, 2016.
\bibitem{b17} Cleary J G, Trigg L E. K * : An Instance-based Learner Using an Entropic Distance Measure[J]. Machine Learning Proceedings, 1995:108-114.
\bibitem{b18} Mascharka D, Manley E. Machine Learning for Indoor Localization Using Mobile Phone-Based Sensors[J]. Computer Science, 2015.
\bibitem{b19} Everett J E. The exponentially weighted moving average applied to the control and monitoring of varying sample sizes[J]. Wit Transactions on Modelling and Simulation, 2011, 51:3-13.


\end{thebibliography}
%\bibliographystyle{IEEEtran}      %IEEEtran为给定模板格式定义文件名
%\bibliography{ref}                        %ref 为.bib文件名
\end{document}
